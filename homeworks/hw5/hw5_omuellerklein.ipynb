{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Oliver Muellerklein\n",
    "\n",
    "Collaboration with Jacob Bukoski and Zhongqi Miao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#sys.path.append('/usr/local/lib/python3.5/site-packages')\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework requires a few steps for database work with SQL tables, building a template with CSV files, and then populating the SQL tables with data pulled from the web with *BeautifulSoup*. Using a utility SQL class and *SQLite3*, I do the initial steps with building the table framework from a blank SQL table and the CSV inferred guidelines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SQL x Weather Underground\n",
    "\n",
    "The first steps are to import some packages for later and create a helper / utility class for SQLite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "\"\"\"Helper utility class for SQL:\n",
    "\n",
    "    * connect(..., database)\n",
    "    \n",
    "    * table_list(...)\n",
    "    \n",
    "    * drop(..., table)\n",
    "    \n",
    "    * close(...)\n",
    "\"\"\"\n",
    "class UtilSQL:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.db = None\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "        \n",
    "    def connect(self, database):\n",
    "        self.db = database\n",
    "        self.connection = sqlite3.connect(self.db)\n",
    "        self.cursor = self.connection.cursor()\n",
    "        \n",
    "    def tableList(self):\n",
    "        sqlCMD = \"select * from sqlite_master where type = 'table';\"\n",
    "        self.cursor.execute(sqlCMD)\n",
    "        dbMeta = self.cursor.fetchall()\n",
    "        for entry in dbMeta: \n",
    "            print(entry)\n",
    "            \n",
    "    def drop(self, table):\n",
    "        sqlCMD = \"drop table %s\" % (table)\n",
    "        self.cursor.execute(sqlCMD)\n",
    "            \n",
    "    def close(self):\n",
    "        self.connection.commit()\n",
    "        self.connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Extract clean dataframe from CSV\n",
    "\n",
    "Next we want to use the given CSVs and extract a cleaner table / data structure for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data from CSV\n",
    "dataHead = pd.read_csv('hw_5_data/top_airports.csv')\n",
    "icao = pd.read_csv('hw_5_data/ICAO_airports.csv')\n",
    "icao = icao.rename(columns = {'iata_code' : 'IATA'})\n",
    "dataMerge = pd.merge(dataHead, icao, on = ['IATA'])\n",
    "dataFin = dataMerge[['ICAO', 'Airport', 'City', 'latitude_deg', 'longitude_deg', 'elevation_ft']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize connection to SQL and begin!\n",
    "\n",
    "Now we can begin to fill in our tables with a connection to our SQL database through our utility class. More below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x11168fab0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to SQL table\n",
    "sql = UtilSQL()\n",
    "sql.connect('HW5.db')\n",
    "\n",
    "# Run SQL commands \n",
    "\n",
    "sqlCMD = \"\"\"CREATE TABLE Top_Airport (ICAO TEXT, Airport TEXT,\n",
    "            City TEXT, Latitude REAL, Longitude REAL, Elevation REAL,\n",
    "            PRIMARY KEY (ICAO))\"\"\"\n",
    "#sql.cursor.execute(sqlCMD)\n",
    "\n",
    "#for i in range(len(dataFin)):\n",
    "#    sqlCMD = (\"INSERT INTO Top_Airport (ICAO, Airport, City, Latitude, Longitude, Elevation) VALUES \" \n",
    "#               + str(tuple(dataFin.ix[i])))\n",
    "#    sql.cursor.execute(sqlCMD)\n",
    "\n",
    "sqlCMD = 'select * from Top_Airport'\n",
    "\n",
    "sql.cursor.execute(sqlCMD)\n",
    "\n",
    "# Show data table (SQL table)\n",
    "#sql.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exploratory steps with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # For Python 3.0 and later\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    # Fall back to Python 2's urllib2\n",
    "    from urllib2 import urlopen\n",
    "    \n",
    "#response = urlopen(\"http://words.bighugelabs.com/\")\n",
    "#html = response.read()\n",
    "#response.close()\n",
    "# pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "#soup = BeautifulSoup(html, \"html5lib\")\n",
    "#forms = soup.findAll(\"form\")\n",
    "#forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "We can begin with an example of how to scrape the **Weather Underground** data for a specific year (2008) using *BeautifulSoup*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#response08 = urlopen(\"https://www.wunderground.com/history/airport/%s/%s/1/1/CustomHistory.html?dayend=31&monthend=12&yearend=%s\" \\\n",
    "#                   % ('KATL', '2008', '2008'))\n",
    "#html08 = response08.read()\n",
    "#response08.close()\n",
    "#soup08 = BeautifulSoup(html08, \"html5lib\")\n",
    "\n",
    "# Try to pull a single year\n",
    "#tbody08 = soup08.find('table', id = 'obsTable', class_ = 'responsive obs-table daily').find_all('tbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Class approach to generating weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways that the database could be connected and integrated with the web scraping of Weather Underground. The following class contains a few different methods and components that allow the data to be built either: \n",
    "\n",
    "**A)** outside of the class by connecting to the SQL data externally, i.e. no data is stored within an instance of this class \n",
    "\n",
    "or \n",
    "\n",
    "**B)** within the class through a mapping to the specific years, i.e. data is stored within an instance of the class \n",
    "\n",
    "I am providing the code here as references to all functionality but the actual data used in the remaining questions imports *hw5.db* - which is a result of using the class without any instance-specific data storage, i.e. option **A**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weather:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.begin = None\n",
    "        self.end = None\n",
    "        self.icao = None\n",
    "        self.tbody = None\n",
    "        self.yearr = None\n",
    "        self.monthh = None\n",
    "        self.dayy = None\n",
    "        self.icao = None\n",
    "        \n",
    "        self.counterr = 0\n",
    "        self.monthIndx = []\n",
    "        self.tryTd = None\n",
    "        self.tbody08 = None\n",
    "        self.tbody09 = None\n",
    "        self.tbody10 = None\n",
    "        self.tbody11 = None\n",
    "        self.tbody12 = None\n",
    "        self.tbody13 = None\n",
    "        self.tbody14 = None\n",
    "        self.tbody15 = None\n",
    "        self.tbody16 = None\n",
    "        self.yyear = None\n",
    "        \n",
    "        # Bunch of maps \n",
    "        self.getNumDayIncrease = {\n",
    "            'Jan' : 32,\n",
    "            'Feb' : 28\n",
    "        }\n",
    "        \n",
    "        self.getTbody = {\n",
    "            2008 : self.tbody08,\n",
    "            2009 : self.tbody09,\n",
    "            2010 : self.tbody10,\n",
    "            2011 : self.tbody11,\n",
    "            2012 : self.tbody12,\n",
    "            2013 : self.tbody13,\n",
    "            2014 : self.tbody14,\n",
    "            2015 : self.tbody15,\n",
    "            2016 : self.tbody16\n",
    "        }\n",
    "\n",
    "    global sql\n",
    "    \n",
    "    def setTbody(self):\n",
    "        \n",
    "        self.tbody = self.getTbody[self.yyear]\n",
    "    \n",
    "    def setTryTD(self):\n",
    "        self.tryTd = self.tbody[self.counterr].find_all('td')[0].string\n",
    "        tryIt = self.trySwitcher()\n",
    "\n",
    "        if (tryIt):\n",
    "            self.tryTd = self.tbody[self.counterr].find_all('td')[0].string\n",
    "            tryIt = self.trySwitcher()\n",
    "      \n",
    "    \n",
    "    def mapSwitcher(self, argument):\n",
    "    \n",
    "        switchh = {\n",
    "            'Jan' : True,\n",
    "            'Feb' : True\n",
    "        }\n",
    "\n",
    "        return switchh.get(argument, 'nothing')\n",
    "\n",
    "    \n",
    "    def trySwitcher(self):\n",
    "        \n",
    "        if (self.mapSwitcher(self.tryTd)):\n",
    "            \n",
    "            # Get index from tbody \n",
    "            self.monthIndx.append(self.counterr)\n",
    "            self.counterr += self.getNumDayIncrease[self.tryTd]\n",
    "            return False\n",
    "\n",
    "        else:\n",
    "            # Try again \n",
    "            self.counterr += 1\n",
    "            return True\n",
    "        \n",
    "    def setYearData(self, icao, yyear):\n",
    "        \n",
    "        self.yyear = yyear\n",
    "        self.getTbody[yyear] = self.fetch(icao, yyear)\n",
    "    \n",
    "    def fetch (self, icao, date):\n",
    "        \"\"\"\n",
    "            Function from Miao: pull specific year stepwise. \n",
    "            Only connections, no internal class storage of tables.\n",
    "            \n",
    "            return: all tbody tags from HTML document (DOM)\n",
    "        \"\"\"\n",
    "\n",
    "        response = urlopen(\"https://www.wunderground.com/history/airport/%s/%s/1/1/CustomHistory.html?dayend=31&monthend=12&yearend=%s\" \\\n",
    "                           % (icao, date, date))\n",
    "        html = response.read()\n",
    "        response.close()\n",
    "        soup = BeautifulSoup(html,\"html5lib\")\n",
    "        tbody = soup.find('table', id = 'obsTable', class_ = 'responsive obs-table daily').find_all('tbody')\n",
    "        return tbody\n",
    "    \n",
    "    def callback (self, row):\n",
    "        \"\"\"\n",
    "            Function from Miao: Callback for iterative year HTML pull of data.\n",
    "        \"\"\"\n",
    "    \n",
    "        if 'avg' in row.text:\n",
    "            self.monthh += 1\n",
    "            self.dayy = 0\n",
    "\n",
    "        #print(self.y, self.m, self.d)\n",
    "\n",
    "        if self.dayy != 0:\n",
    "            td = row.find_all('td')\n",
    "\n",
    "            MaxT = td[2].text.strip()\n",
    "            MeanT = td[1].text.strip()\n",
    "            MinT = td[3].text.strip()\n",
    "            MaxH = td[8].text.strip()\n",
    "            MeanH = td[7].text.strip()\n",
    "            MinH = td[9].text.strip()\n",
    "            Prep = td[-2].text.strip()\n",
    "            Date = datetime(self.yearr, self.monthh, self.dayy).date()\n",
    "            \n",
    "            sql.cursor.execute(\"\"\"INSERT INTO Weather (ICAO, Date, MaxT, MeanT,\n",
    "                            MinT, MaxH, MeanH, MinH, Prep) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                                  (self.icao, Date, MaxT, MeanT, MinT, MaxH, MeanH, MinH, Prep))\n",
    "\n",
    "        self.dayy += 1\n",
    "    \n",
    "    def popData (self, begin, end, icao):\n",
    "        \"\"\"\n",
    "            Function from Miao: populate SQL table externally.\n",
    "            Steps through each year of data and increments / counts \n",
    "            months and days - accounts for leap years etc. \n",
    "        \"\"\"\n",
    "    \n",
    "        self.icao = icao\n",
    "        \n",
    "        for i in range(begin, end + 1):\n",
    "\n",
    "            tbody = self.fetch(icao, i)\n",
    "            self.yearr = i\n",
    "            self.monthh = 0\n",
    "            self.dayy = 0\n",
    "            a = list(map(self.callback, tbody))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a beginning example of using the **Weather** class to manually step through the years and months, iterively augmenting the data to the data map. *Note: the complete code for not incorporating the data into the class (which is the method we used to directly create the database file) is included below in the comments.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weatherInst = Weather()\n",
    "weatherInst.setYearData('KATL', 2008)\n",
    "weatherInst.setTbody()\n",
    "len(weatherInst.getTbody[2008])\n",
    "weatherInst.setTryTD()\n",
    "\n",
    "# Counterr is used to count through number of days per month \n",
    "#weatherInst.counterr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And here is the code for looping through and populating the SQL table directly, *i.e. this is the method that connects to and populates the SQL table externally without storing the data internally (in the class instance).*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  KATL\n",
      "i:  KORD\n",
      "i:  KLAX\n",
      "i:  KDFW\n",
      "i:  KDEN\n",
      "i:  KJFK\n",
      "i:  KSFO\n",
      "i:  KIAH\n",
      "i:  KLAS\n",
      "i:  KPHX\n",
      "i:  KCLT\n",
      "i:  KMIA\n",
      "i:  KMCO\n",
      "i:  KEWR\n",
      "i:  KDTW\n",
      "i:  KMSP\n",
      "i:  KSEA\n",
      "i:  KPHL\n",
      "i:  KBOS\n",
      "i:  KLGA\n",
      "i:  KIAD\n",
      "i:  KBWI\n",
      "i:  KFLL\n",
      "i:  KSLC\n",
      "i:  PHNL\n",
      "i:  KDCA\n",
      "i:  KMDW\n",
      "i:  KSAN\n",
      "i:  KTPA\n",
      "i:  KPDX\n",
      "i:  KSTL\n",
      "i:  KMCI\n",
      "i:  KMEM\n",
      "i:  KCLE\n",
      "i:  KOAK\n",
      "i:  TJSJ\n",
      "i:  KRDU\n",
      "i:  KBNA\n",
      "i:  KSMF\n",
      "i:  KHOU\n",
      "i:  KSNA\n",
      "i:  KAUS\n",
      "i:  KSJC\n",
      "i:  KMSY\n",
      "i:  KPIT\n",
      "i:  KSAT\n",
      "i:  KCVG\n",
      "i:  KMKE\n",
      "i:  KDAL\n",
      "i:  KIND\n"
     ]
    }
   ],
   "source": [
    "weatherInst = Weather()\n",
    "for i in dataFin[\"ICAO\"]:\n",
    "    \n",
    "    # i = the top 50 airports\n",
    "    \n",
    "    print(\"i: \", i)\n",
    "    #weatherInst.popData(2008, 2016, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation coefficient directly on SQL table\n",
    "\n",
    "The next major step is calculating the correlation coefficient across all of the data. This could be performed after extracting the data into standard *Python* data structures / code, *i.e. Numpy arrays and use of numpy.corrcoeff()*. However, for greater optimization and learning purposes, the correlation coefficients are calculated directly on the SQL table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to SQL table\n",
    "sql = UtilSQL()\n",
    "sql.connect('HW5.db')\n",
    "\n",
    "sql_cmd = \"\"\"select w1.icao, w1.date, w1.Prep, w2.icao, w2.date, w2.Prep\n",
    "             from Weather w1, Weather w2 \n",
    "             where strftime('%Y', w1.date) = strftime('%Y', w2.date)\n",
    "             and strftime('%m', w1.date) = strftime('%m', w2.date)\n",
    "             and strftime('%d', w1.date) = strftime('%d', w2.date)\n",
    "             and w1.icao='KATL' \n",
    "             and w2.icao='KORD' \n",
    "             and typeof(w1.Prep)='real'\n",
    "             and typeof(w2.Prep)='real';\"\"\"\n",
    "sql.cursor.execute(sql_cmd)\n",
    "result = sql.cursor.fetchall()\n",
    "# len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p_c (icao):\n",
    "\n",
    "    global sql\n",
    "    \n",
    "    sql_cmd = \"\"\"select w1.Prep\n",
    "                 from Weather w1 \n",
    "                 where w1.icao='%s' \n",
    "                 and typeof(w1.Prep)='real';\"\"\" % (icao)\n",
    "    sql.cursor.execute(sql_cmd)\n",
    "    result = sql.cursor.fetchall()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1bc34b20ccaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KORD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KORD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/echoes/miniconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/echoes/miniconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2483\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2484\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/echoes/miniconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/echoes/miniconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2798\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "test = p_c('KATL') \n",
    "\n",
    "test = pd.DataFrame(test, columns = {'KATL'})\n",
    "\n",
    "test1 = p_c('KORD') \n",
    "\n",
    "test['KORD'] = test1\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdTable = pd.DataFrame()\n",
    "\n",
    "# rows = p\n",
    "# cols = airports \n",
    "pdTable.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note about covariance matrices \n",
    "\n",
    "We will be using the **numpy** function *np.corrcoeff* to calculate a normalized covariance matrix of our database. The normalized covariance matrix is calculated with the following:\n",
    "\n",
    "```\n",
    "    * n = number of observations \n",
    "    * p = number of predictors \n",
    "    * n x p = dimensions of the data \n",
    "    * N = [n_1, n_2, ... , n_z]**T - all observations transposed\n",
    "    * C_ij = covariance of n_i and n_j\n",
    "    * C_ii = variance of n_i\n",
    "    * R_ij = C_ij / sqrt(C_ii * C_jj)\n",
    "```\n",
    "\n",
    "The covariance is calculated using N (the observations transposed) and produces a **n x n** matrix with the following values: \n",
    "\n",
    "```\n",
    "    If the value of C_ij is close to 1: \n",
    "        near perfect positive linear relationship / correlation between n_i and n_j\n",
    "    If the value of C_ij is close to -1:\n",
    "        near perfect negative linear relationship / correlation between n_i and n_j\n",
    "    If the value of C_ij is 0:\n",
    "        no relationship between n_i and n_j\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Speed up the calculation of the covariance \n",
    "def speedUpCov(Ni, Nj):\n",
    "    Nim = np.reshape(np.mean(Ni, axis = 1), (Ni.shape[0], 1))\n",
    "    Njm = np.mean(Nj)\n",
    "    Cij = np.sum((Ni - Nim) * (Nj - Njm), axis = 1)\n",
    "    Ciijj = np.sqrt(np.sum((Ni - Nim)**2, axis = 1) * np.sum((Nj - Njm)**2))\n",
    "    Rij = Cij / Ciijj\n",
    "    return Rij\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
