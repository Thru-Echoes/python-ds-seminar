{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 7 \n",
    "\n",
    "### Oliver Muellerklein with Miao and Jacob B. \n",
    "\n",
    "Note: I had taken Miao to the E.R. on Thursday night after we had been working with Jacob on developing this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import skimage\n",
    "from skimage.util.shape import view_as_windows\n",
    "from skimage.util.montage import montage2d\n",
    "from scipy.cluster.vq import kmeans2\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_mean\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import equalize_hist\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getWorkDir():\n",
    "    return os.getcwd()\n",
    "\n",
    "def setWorkDir(newPath):\n",
    "    os.chdir(newPath)\n",
    "    print(\"\\nNew working directory: \", os.getcwd())\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWorkDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image ploting function\n",
    "def show_images(images, titles=None, interpolation = 'nearest'):\n",
    "    \"\"\"Display a list of images\"\"\"\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1 ,n_ims, n)\n",
    "        if image.ndim == 2: plt.gray()\n",
    "        plt.imshow(image, interpolation = interpolation)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_img_dict(is_sample = False):\n",
    "    \n",
    "    #Generates a {name : index} dictionary for each of the image categories.\n",
    "      \n",
    "    if is_sample:\n",
    "        path = os.path.join(os.getcwd(), 'sample_img/') \n",
    "    else:\n",
    "        path = os.path.join(os.getcwd(), '50_categories/')\n",
    "    \n",
    "    categories = []\n",
    "    index = 0\n",
    "    img_types = {}\n",
    "    \n",
    "    img_type_names = os.listdir(path)\n",
    "    img_type_names.sort()\n",
    "    \n",
    "    for direc in img_type_names:\n",
    "        if direc.startswith('.') == False:\n",
    "            index = index + 1\n",
    "            img_types[direc] = [index]\n",
    "            \n",
    "    return(img_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def montage_wb_ratio(input_image, patch_shape, n_filters, ele_print = False):\n",
    "\n",
    "    patches = view_as_windows(input_image, patch_shape)\n",
    "    patches = patches.reshape(-1, patch_shape[0] * patch_shape[1])[::8]\n",
    "    fb, _ = kmeans2(patches, n_filters, minit = 'random')\n",
    "    fb = fb.reshape((-1,) + patch_shape)\n",
    "    fb_montage = montage2d(fb, fill = False, rescale_intensity = True)\n",
    "    shape_var = np.ceil(np.sqrt(n_filters))\n",
    "    elements = np.split(np.hstack(np.split(fb_montage, shape_var)), shape_var**2, axis = 1)\n",
    "    del elements[n_filters:]\n",
    "    wb_ratios = []\n",
    "    bin_elements = []\n",
    "    \n",
    "    for element in elements:\n",
    "        thresh = threshold_mean(element)\n",
    "        binary = element > thresh\n",
    "        ratio = np.sum(binary) / binary.size\n",
    "        wb_ratios.append(ratio)\n",
    "        \n",
    "        if ele_print:\n",
    "            bin_elements.append(binary)\n",
    "\n",
    "    wb_ratios = sorted(wb_ratios, reverse = True)\n",
    "    \n",
    "    if ele_print:\n",
    "        show_images(elements)\n",
    "        show_images(bin_elements)\n",
    "    \n",
    "    return(wb_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Summary Stats of RGB Channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rgb_summary(img):\n",
    "        img_r = img[:, :, 0]\n",
    "        img_g = img[:, :, 1]\n",
    "        img_b = img[:, :, 2]\n",
    "        \n",
    "        r_mean = np.mean(img_r)\n",
    "        r_median = np.median(img_r)\n",
    "        r_std = np.std(img_r)\n",
    "        r_var = np.var(img_r)\n",
    "        \n",
    "        g_mean = np.mean(img_g)\n",
    "        g_median = np.median(img_g)\n",
    "        g_std = np.std(img_g)\n",
    "        g_var = np.var(img_g)\n",
    "        \n",
    "        b_mean = np.mean(img_b)\n",
    "        b_median = np.median(img_b)\n",
    "        b_std = np.std(img_b)\n",
    "        b_var = np.var(img_b)\n",
    "        \n",
    "        return list([r_mean, r_median, r_std, r_var, g_mean, g_median, g_std, g_var, b_mean, b_median, b_std, b_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITIONS\n",
    "# Quick function to divide up a large list into multiple small lists, \n",
    "# attempting to keep them all the same size. \n",
    "def split_seq(seq, size):\n",
    "    newseq = []\n",
    "    splitsize = 1.0 / size * len(seq)\n",
    "    for i in range(size):\n",
    "        newseq.append(seq[int(round(i * splitsize)):int(round((i + 1) * splitsize))])\n",
    "    return newseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(input_image):\n",
    "    gray = rgb2gray(input_image)\n",
    "    hist = equalize_hist(gray)\n",
    "    return hist\n",
    "\n",
    "def extract_features(image_path_list):\n",
    "    \n",
    "    feature_list = []\n",
    "    \n",
    "    for image_path in image_path_list:\n",
    "        one_row = []\n",
    "        category = image_path.split('/')[-2]\n",
    "        one_row.extend([image_path, category])\n",
    "        image_array = io.imread(image_path)\n",
    "        processed_image = preprocess(image_array)\n",
    "        \n",
    "        ##############\n",
    "        \n",
    "        #with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        wb = montage_wb_ratio(processed_image, (8, 8), 25, ele_print = False)\n",
    "        \n",
    "        #get RGB summary stats \n",
    "        rgb_summary = get_rgb_summary(image_array)\n",
    "        \n",
    "        #concatenate features\n",
    "        wb_and_rgb = wb + rgb_summary\n",
    "\n",
    "        #one_row.extend(wb)\n",
    "        one_row.extend(wb_and_rgb)\n",
    "        feature_list.append(one_row)\n",
    "        \n",
    "    return feature_list\n",
    "\n",
    "def new_data_read(image_path):\n",
    "    image_array = io.imread('test6.jpg')\n",
    "    processed_image = preprocess(image_array)\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    wb = montage_wb_ratio(processed_image, (8, 8), 25, ele_print = False)\n",
    "    return wb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_feat(is_sample = False):\n",
    "\n",
    "    MYDIRECTORY = os.getcwd()\n",
    "    \n",
    "    if is_sample:\n",
    "        categories = os.listdir(MYDIRECTORY + '/sample_img')\n",
    "    else:\n",
    "        categories = os.listdir(MYDIRECTORY + '/50_categories')\n",
    "    image_paths = []\n",
    "\n",
    "    for category in categories:\n",
    "        if not category.startswith('.'):\n",
    "            if is_sample:\n",
    "                image_names = os.listdir(MYDIRECTORY + \"/sample_img/\" + category)\n",
    "            else:\n",
    "                image_names = os.listdir(MYDIRECTORY + \"/50_categories/\" + category)\n",
    "                \n",
    "            for name in image_names:\n",
    "                if is_sample:\n",
    "                    image_paths.append(MYDIRECTORY + \"/sample_img/\" + category + \"/\" + name)\n",
    "                else:\n",
    "                    image_paths.append(MYDIRECTORY + \"/50_categories/\" + category + \"/\" + name)\n",
    "\n",
    "    # Then, we run the feature extraction function using multiprocessing.Pool so \n",
    "    # so that we can parallelize the process and run it much faster.\n",
    "    numprocessors = cpu_count() \n",
    "\n",
    "    # We have to cut up the image_paths list into the number of processes we want to\n",
    "    # run. \n",
    "    split_image_paths = split_seq(image_paths, numprocessors)\n",
    "\n",
    "    # Ok, this block is where the parallel code runs. We time it so we can get a \n",
    "    # feel for the speed up.\n",
    "    start_time = time()\n",
    "    p = Pool(numprocessors)\n",
    "    result = p.map_async(extract_features, split_image_paths)\n",
    "    poolresult = result.get()\n",
    "    end_time = time()\n",
    "    \n",
    "    # All done, print timing results.\n",
    "    print (\"Finished extracting features. Total time: \" + \n",
    "        str(round(end_time-start_time, 3)) + \" s, or \" + \n",
    "        str(round((end_time-start_time) / len(image_paths), 5)) + \" s/image.\")\n",
    "\n",
    "    # To tidy-up a bit, we loop through the poolresult to create a final list of\n",
    "    # the feature extraction results for all images.\n",
    "    combined_result = []\n",
    "    for single_proc_result in poolresult:\n",
    "        for single_image_result in single_proc_result:\n",
    "            combined_result.append(single_image_result)\n",
    "            \n",
    "    if is_sample: \n",
    "        cate = set_img_dict(is_sample = True) \n",
    "    else:\n",
    "        cate = set_img_dict(is_sample = False)\n",
    "        \n",
    "    combined_result = np.array(combined_result)\n",
    "    X = combined_result[:, 2:]\n",
    "    Y = combined_result[:, 1]\n",
    "    for i in range(len(Y)):\n",
    "        Y[i] = cate[Y[i]][0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Functions for generating and dumping model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fitting(X, Y, dump_file = 'model.p'):\n",
    "    grid_models = GridSearchCV(RandomForestClassifier(),\n",
    "                       {'n_estimators':range(200, 1000, 100)}, n_jobs = 8, cv = 10)\n",
    "    fit_models = grid_models.fit(X, Y)\n",
    "    return fit_models\n",
    "\n",
    "def get_pickle_model(modelz, dump_file = 'model.p'):\n",
    "    \n",
    "    # Save out only best model \n",
    "    if dump_file:\n",
    "        with open(dump_file, \"wb\") as fp:\n",
    "            #joblib.dump(modelz.best_estimator_, fp, protocol = pickle.HIGHEST_PROTOCOL, compression = 9)\n",
    "            joblib.dump(modelz.best_estimator_, fp, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    return modelz.best_estimator_\n",
    "\n",
    "def load_model(model_file = 'model.p'):\n",
    "    with open(model_file, \"rb\") as fp:\n",
    "        model_instance = joblib.load(fp)\n",
    "    return model_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run Algorithm \n",
    "\n",
    "Our process involves: \n",
    "\n",
    "1. Data featurization - generate features from all images to create our dataset for machine learning \n",
    "2. Model fitting - use Grid Search Cross Validation, K-fold CV, to find the best parameters for the model (via Random Forest) \n",
    "3. Dump model - compress and dump Pickle model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWorkDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New working directory:  /Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setWorkDir(os.path.join(os.getcwd(), 'sample_img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWorkDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img/sample_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c89e4727d00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#X, Y = get_data_feat(is_sample = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-68da4929d951>\u001b[0m in \u001b[0;36mget_data_feat\u001b[0;34m(is_sample)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMYDIRECTORY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/sample_img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMYDIRECTORY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/50_categories'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kschocz/Documents/berkeley-courses/second-year/fall16/python-ds-seminar/homeworks/hw7/sample_img/sample_img'"
     ]
    }
   ],
   "source": [
    "X, Y = get_data_feat(is_sample = True)\n",
    "\n",
    "#X, Y = get_data_feat(is_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_fits = model_fitting(X, Y, dump_file = 'model.p')\n",
    "pickle_model = get_pickle_model(sample_fits, dump_file = 'model.p')\n",
    "\n",
    "#fitted_models = model_fitting(X, Y, dump_file = 'model.p')\n",
    "#pickle_model = get_pickle_model(fitted_models, dump_file = 'model.p')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
